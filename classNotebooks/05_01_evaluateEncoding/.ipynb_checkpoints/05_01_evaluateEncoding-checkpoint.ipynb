{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Encoding Models\n",
    "\n",
    "The goal of today's notebook is for you to examine the goodness of fit of your linear and nonlinear models for the H1 neuron.\n",
    "\n",
    "As before, the first cell loads the data. There is no need to alter anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages to load data\n",
    "import scipy.io as sio\n",
    "\n",
    "# Load the file and parse the variables\n",
    "H1 = sio.loadmat('H1.mat')\n",
    "rho = H1['rho']\n",
    "stim = H1['stim']\n",
    "\n",
    "# Making them one dimensional to do further calculations\n",
    "rho = rho[:,0]\n",
    "stim = stim[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to more directly compare the models to the neural response, we want to create a smoothed firing rate. Use convolution along with the given kernel to create a 21-point moving average across the spike train vector, rho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an 11-point moving window to smooth out the spike train\n",
    "from numpy.matlib import repmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# kernel is 21 point moving window\n",
    "kernel = repmat(.05, 1, 21).ravel()\n",
    "\n",
    "# smooth rho with kernel\n",
    "smoothRho = #FILL ME IN\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(rho[0:1000])\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(smoothRho[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create the linear model, you will need to convolve your spike-triggered average with the stimulus. In the interest of time, you may load in the pre-computed STA provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load STA and create linear model\n",
    "STA = np.load('STA.npy')\n",
    "\n",
    "# Create linear model by convolving stimulus with STA (use 'same' method)\n",
    "linearModel = #fill me in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure the goodness of fit between these two models, we can examine both the Pearson correlation coefficient as well as the coefficient of determination. Fill in the code below to display these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The correlation is: ',np.corrcoef(XXX, XXX)[X,X])\n",
    "print('Proportion of explained variance: ',# fill this in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the nonlinear model, we need to do two things: z-score the linear model to reduce the range to something sensible, and then pass it through a sigmoid function. Fill in the code below to accomplish these goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score the linear model\n",
    "linearModel = #fill me in\n",
    "\n",
    "# pass the result through the sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0+np.exp(-x))\n",
    "\n",
    "nonlinearModel = sigmoid(#fill me in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, print out the Pearson correlation coefficient and the coefficient of determination for the nonlinear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The correlation is: ',np.corrcoef(XXX, XXX)[X,X])\n",
    "print('Proportion of explained variance: ',# fill this in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is better? How can you tell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check how well each model generalizes. We will fit a model to the first half of the dataset, and use it to predict the values of the smoothed spike train from the second half of the dataset (we are ignoring habituation, learning, etc.)\n",
    "\n",
    "Break up the dataset (smooth rho and stim) into two halves. On the first half, create a linear model in the same method as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break up dataset into first and second halves\n",
    "\n",
    "# create the linear model of the first half\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get the slope and intercept parameters for this model. For now, we'll do it by hand.\n",
    "\n",
    "Remember that the equation for the regression coefficients is:\n",
    "$$w = (X^TX)^{-1} X^TY$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "# put smooth rho and linear model into matrix form\n",
    "\n",
    "# add a column of ones to your \"X\" variable\n",
    "\n",
    "# calculate XtX and XtY\n",
    "\n",
    "# calculate w\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to apply the coefficients that you just calculated to the data from the second half of the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAxis = np.linspace(0, .7, len(smoothRho2))\n",
    "\n",
    "yHat = w[0] + w[1]*xAxis\n",
    "\n",
    "print('The correlation is: ',np.corrcoef(smoothRho2, yHat)[0,1])\n",
    "print('Proportion of explained variance: ', np.corrcoef(smoothRho2, yHat)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, not that great. But it's very hard to build a model that has strong generalization. On the plus side, you can see that there is plenty of room left to build better models in computational neuroscience!\n",
    "\n",
    "Please upload this file to Lyceum for grading. Wonderful job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
