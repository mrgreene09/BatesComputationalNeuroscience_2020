{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:black\">Neural Decoding</span>\n",
    "\n",
    "\n",
    "In lab, we will be working with files in the Zhang_neurons folder. This dataset contains recordings from 132 neurons in a monkey's inferior temporal lobe (IT). an area known to be highly involved in high-level vision and object perception. The recordings were made while a monkey viewed 7 different objects that were presented at each of three screen locations. Each object was presented approximately 20 times at each of the three locations. In each trial, the monkey viewed a fixation dot for 500 ms, and then viewed one of the seven objects for another 500 ms. The data were reported in Zhang et al (2011, *PNAS*). \n",
    "\n",
    "Note: This paper contains conditions in which objects were presented simultaneously, but only the single object condition is included.\n",
    "\n",
    "Zhang, Y., Meyers, E. M., Bichot, N. P., Serre, T., Poggio, T. A., & Desimone, R. (2011). *Object decoding with attention in inferior temporal cortex*. Proceedings of the National Academy of Sciences, 108(21), 8850-8855.\n",
    "\n",
    "https://doi.org/10.1073/pnas.1100999108\n",
    "\n",
    "### About the dataset:\n",
    "\n",
    "The data are in raster format, meaning that each .mat file contains data from one of the 132 neurons. Each of these files contains three variables.\n",
    "\n",
    "*raster_site_info*: A structure corresponding to the recording parameters of the experiment that <u>can be ignored</u> for the purpose of this problem set.\n",
    "\n",
    "*raster_labels*: A structure that contains the object being viewed (stimulus_ID), the position of the object (stimulus_position), and the combined object+position (combined_ID_position).\n",
    "\n",
    "*raster_data*: A matrix where each row corresponds to the data from one trial, and each column corresponds to data from one 1-ms time point (the rows are also in order so that the first trial is in the first row, and the last trial is in the last row).\n",
    "\n",
    "### Working with the dataset:\n",
    "\n",
    "Dealing with 132 separate data files can be a challenge. First, import these packages and define some helpful code snippets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mat2array import loadmat\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the path to the current directory on your computer\n",
    "homeDirectory = os.getcwd()\n",
    "\n",
    "# Change the directory to the directory containing the raw data\n",
    "os.chdir(homeDirectory+ '/Zhang_neurons')\n",
    "\n",
    "# Create a file list of all neurons' data files\n",
    "neuronList = glob.glob('*.mat')\n",
    "\n",
    "# Change directory back to home\n",
    "os.chdir(homeDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I recommend reading the files in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops through each file in neuronList\n",
    "for i in range(len(neuronList)):  \n",
    "    # creates a full path on your computer to the ith file\n",
    "    path = homeDirectory + '/Zhang_neurons/' + neuronList[i]\n",
    "    \n",
    "    # loads the file\n",
    "    neuron = loadmat(path)\n",
    "    \n",
    "    # parses the data into the relevant variables\n",
    "    raster_data = neuron['raster_data']\n",
    "    stimID = neuron['raster_labels']['stimulus_ID']\n",
    "    stimPosition = neuron['raster_labels']['stimulus_position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will only concern ourselves with the seven object identities. It's helpful to define them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['car','couch','face','flower','guitar','hand','kiwi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the indices of the first class (car), you could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carInd, = np.where(stimID == classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all IT neurons are equally responsive to visual stimuli. Calculate the mean spike count rate for each neuron in the interval from 601-1000 ms and plot a histogram of the population's spiking rate. (We're omitting the first 100 ms because there is little visually-driven activity in this area during this period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data storage for the average firing rate of each neuron\n",
    "meanRate = np.zeros()\n",
    "\n",
    "# Loop through each neuron in neuronList\n",
    "for i in range():  \n",
    "    # Define the file path for loading the .mat files\n",
    "    \n",
    "    # Use the loadmat function to load the file\n",
    "    \n",
    "    # Defining the data stored in the .mat file\n",
    "    raster_data = neuron['raster_data']\n",
    "    stimID = neuron['raster_labels']['stimulus_ID']\n",
    "    stimPosition = neuron['raster_labels']['stimulus_position']\n",
    "    \n",
    "    # Calculate the mean spike count rate for each neuron and store in meanRate\n",
    "\n",
    "# Plotting\n",
    "plt.hist(meanRate);\n",
    "plt.title('Histogram of population firing rates')\n",
    "plt.xlabel('Firing rate')\n",
    "plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2-3 sentences:\n",
    "\n",
    "What do you conclude about the visual responsiveness to this population? What might be a negative consequence of decoding using these raw firing rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to turn the raw raster plots into spike-count rate matrices. I have provided you with a function that computes the firing rate matrix for a neuron and creates a 420-trial by 18-time bin matrix in which each time bin represents the spike count rate for a neuron within the time window. The time bins begin every 50 ms (1 ms, 51 ms, 101 ms, etc), and are 150 ms long. Thus, time window 1 is from 1-150, window 2 is from 51-200, etc. \n",
    "\n",
    "Run this cell to define the function and see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = loadmat('Zhang_neurons/bp1001spk_01A_raster_data.mat')\n",
    "\n",
    "def rate(neuron):\n",
    "    global bins\n",
    "    bins = np.arange(0,890,50)\n",
    "    rateMat = np.zeros((420,18))\n",
    "    raster_data = neuron['raster_data']\n",
    "    for i in range(len(bins)):\n",
    "        rate1 = raster_data[:,bins[i]:bins[i]+150]\n",
    "        rate2 = np.sum(rate1,axis=1)\n",
    "        rate3 = rate2/.15\n",
    "        rateMat[:,i] = rate3\n",
    "    \n",
    "    return rateMat\n",
    "\n",
    "# Example using the new function\n",
    "rateMat = rate(neuron)\n",
    "print(rateMat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fix the problems you outlined above, you want to z-score the firing rates for this neuron. Recall that a z-score is calculated as follows:\n",
    "$$z = \\frac{x-\\mu}{\\sigma}$$ \n",
    "\n",
    "Where $x$ is the raw firing rate, $\\mu$ is the mean firing rate, and $\\sigma$ is the standard deviation of the cell's firing rate.\n",
    "\n",
    "Use the zScore function to find the z-score of your firing rate matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zScore(rateMat): \n",
    "    globalMean = np.mean(rateMat)\n",
    "    globalSTD = np.std(rateMat)\n",
    "    z = (rateMat - globalMean)/globalSTD\n",
    "    return z\n",
    "\n",
    "# Apply the zScore function to your firing rate matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a 3-dimensionsal matrix of z-scored firing rates for each of the neuron. The purpose of this is to decode by the entire population of neurons at each time point. \n",
    "\n",
    "<img src=\"image2.jpg\" alt=\"drawing\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data structures\n",
    "trialInds = np.zeros() # hint: should be the same as the number of trials\n",
    "dataMat = np.zeros() # hint: should be N-trials by M-time points by 125 valid neurons\n",
    "\n",
    "# start a neuron count at 0\n",
    "count = 0\n",
    "\n",
    "# loop through each neuron file\n",
    "for i in range():\n",
    "    # Define the file path for loading the .mat files\n",
    "    \n",
    "    # Use the loadmat function to load the file\n",
    "    \n",
    "    # Defining the data stored in the .mat file\n",
    "    raster_data = neuron['raster_data']\n",
    "    stimID = neuron['raster_labels']['stimulus_ID']\n",
    "    stimPosition = neuron['raster_labels']['stimulus_position']\n",
    "\n",
    "    # Check if the neuron has the full number of trials\n",
    "    if raster_data.shape[0] == :\n",
    "        \n",
    "        # If so, Calculate rate and zScores of the neuron\n",
    "        rateMat = rate()\n",
    "        z = zScore()\n",
    "        \n",
    "        # We need to sort the data by trial type to make our lives easier later\n",
    "        sortedTrials = sorted(enumerate(trialInds), key=lambda x:x[1])\n",
    "        sortedTrials = np.asarray(sortedTrials)\n",
    "        sortedData = sortedTrials[:,0].astype(int)\n",
    "        allClasses = sortedTrials[:,1].astype(int)\n",
    "        \n",
    "        # place sorted data into array\n",
    "        dataMat[:,:,count] = z[sortedData,:]\n",
    "        \n",
    "        # increment valid cell counter\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data structure, we will do the actual decoding. \n",
    "\n",
    "Our goal is to apply our SVM classifier to each of the 18 time points. For each time point, each of the 125 neurons is a feature, and we will use 10-fold cross validation. We will calculate and plot the classifier's accuracy given the population and time point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary machine learning tools\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn import svm\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "\n",
    "# Define categories\n",
    "classes = ['car','couch','face','flower','guitar','hand','kiwi']\n",
    "\n",
    "# initialize accuracy data structure (hint: there will be one accuracy for each time bin)\n",
    "totalAccuracy = np.zeros()\n",
    "\n",
    "# loop through each of the 18 time bins\n",
    "for t in range():\n",
    "    \n",
    "    # Define 420x125 feature matrix per time bin\n",
    "    timeMat = dataMat[]\n",
    "    \n",
    "    # Define random indices for 10-fold cross validation\n",
    "    randInds = np.random.randint(0, high=10, size=(420))\n",
    "    \n",
    "    # 10-fold cross validation\n",
    "    for j in range():\n",
    "        \n",
    "        # define testing data for this fold\n",
    "        testInds = \n",
    "        testVec = allClasses[]\n",
    "        testData = timeMat[]\n",
    "        \n",
    "        # define training data for this fold\n",
    "        trainInds = \n",
    "        trainVec = allClasses[]\n",
    "        trainData = timeMat[]\n",
    "        \n",
    "        # train the SVM classifier\n",
    "        classify.fit(trainData,trainVec)\n",
    "        \n",
    "        # get classifier's predictions on testing data\n",
    "        predClass = classify.predict()\n",
    "        \n",
    "        # Initialize data storage to calculate accuracy for each item in this fold\n",
    "        accuracy = np.zeros()\n",
    "        \n",
    "        # Check the accuracy of each item\n",
    "        for h in range():\n",
    "            # Conditional to check accuracy of predClass with respect to testVec\n",
    "            \n",
    "    # Average over the accuracies in each fold to yeild an overall accuracy for the time bin\n",
    "    totalAccuracy[t] = \n",
    "    \n",
    "# Plot accuracy of population with respect to each time bin\n",
    "plt.figure()\n",
    "plt.plot(bins, totalAccuracy)\n",
    "plt.xlabel(\"Fill me in\")\n",
    "plt.ylabel(\"Fill me in\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went according to plan, your decoding graph should look qualitatively similar to the blue curve from the original paper:\n",
    "\n",
    "<img src=\"image1.png\" alt=\"drawing\" width=\"250\"/>\n",
    "\n",
    "Note: Zhang et al used a different type of classifier, so your accuracies will be somewhat different.\n",
    "\n",
    "Congrats! This is a big project! Please upload this notebook to Lyceum for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
