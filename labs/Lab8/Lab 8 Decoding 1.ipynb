{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:black\">Intro to Neural Decoding</span>\n",
    "\n",
    "Neural decoding is the study of what information is available in the electrical activity of individual cells or networks of neurons by trying to identify what stimulus or event elicits a particular pattern of neural activity.\n",
    "\n",
    "It can be used predict what people were dreaming about, imagining, looking at or listening too, among many other exciting areas of interest.\n",
    "\n",
    "In this tutorial, we will go through a few different ways to decode your neural data. This lab will also introduce you to the data that we will be using for our last problem set.\n",
    "\n",
    "### Part 1: Classifying by computing distance to centroid\n",
    "\n",
    "Here, we will generate two slightly separated clusters of random data. This will serve as our training set. We will then generate test points drawn from both of our distributions. We will compute the distance of each test point to the center of both clusters and use the smallest distance as our prediction. We will then test the accuracy of our prediction.\n",
    "\n",
    "Run the cell below. There is no need to change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing helful packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random number seed to make results replicable\n",
    "np.random.seed(10)\n",
    "\n",
    "# Define parameters of two data clusters\n",
    "m1 = np.array([0.05, 0.05])\n",
    "m2 = np.array([0.95, 0.95])\n",
    "sigma = np.eye(2)\n",
    "\n",
    "# Generate 100 data points from each cluster as training data\n",
    "data1 = np.random.multivariate_normal(m1,sigma,100)\n",
    "data2 = np.random.multivariate_normal(m2,sigma,100)\n",
    "\n",
    "# Plot the data: make a scatterplot with data1 as blue circles and data2 as red circles\n",
    "plt.figure()\n",
    "plt.scatter(data1[:,0], data1[:,1], c='blue')\n",
    "plt.scatter(data2[:,0], data2[:,1], c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a loop of 100 steps, generate a test point either from m1 50% of the time and from m2 50% of the time. Using the imported pdist() function, compute the distance of your point to both means, and assign the point to the nearest mean. Record an accuracy of 1 for each trial if the correct mean is guessed, and record a 0 if it is not. What is your mean accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pdist function\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Initialize data structures\n",
    "accuracy = np.zeros() # fill in the parentheses according to the instructions\n",
    "mat1 = np.zeros((2,2))\n",
    "mat2 = np.zeros((2,2))\n",
    "\n",
    "# Loop to create and classify points\n",
    "for i in range():\n",
    "    # Conditional to randomly pick a point from m1 or m2\n",
    "\n",
    "    # Define test point \n",
    "    myPoint = np.random.multivariate_normal(myMean, sigma, 1)\n",
    "    \n",
    "    # calculate the distance to m1 and m2 (row 0: myPoint; row1: m1 or m2)\n",
    "    mat1[0,:] = \n",
    "    mat1[1,:] = \n",
    "    mat2[0,:] = \n",
    "    mat2[1,:] = \n",
    "    \n",
    "    dist1 = pdist()\n",
    "    dist2 = pdist()\n",
    "    \n",
    "    # Conditional to assign predicted class to be the class w/ smallest distance\n",
    "\n",
    "    # Conditional to determine trial accuracy\n",
    "\n",
    "# Calculate mean accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Correlation Classifier\n",
    "\n",
    "For multivariate classifications, a simple but still powerful classification algorithm is the correlation classifier. Here, each feature of the input is correlated to the mean of each class observed in training, and the class that is most correlated with the rest item is taken to be the classifier's prediction.\n",
    "\n",
    "For this exercise, we will use one single neuron from the Zhang et al (2011) PNAS. Next week, you will be using the whole population of over 100 neurons that were recorded!\n",
    "\n",
    "The data are stored in the classificationData.mat file. In this structure, neuronData corresponds to the spike count rate of a single neuron in the object-sensitive inferior temporal cortex in 150 ms bins over course of each of 420 trials. In this experiement, a monkey was viewing one of 7 objects, and the indices for each of these objects is in neuronInds. Finally, neuronLabels gives gives the object names in order. In other words, the second position of neuronLabels gives the object that corresponds to all of the 2's in neuronInds.\n",
    "\n",
    "Run the code below to load the data and to show you the shape of neuronData and the neuronLabels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing package to load data\n",
    "from mat2array import loadmat\n",
    "\n",
    "# Loading and defining data\n",
    "classificationData = loadmat('classificationData.mat')\n",
    "neuronData = classificationData['neuronData']\n",
    "neuronInds = classificationData['neuronInds']\n",
    "neuronLabels = classificationData['neuronLabels']\n",
    "\n",
    "print(neuronData.shape)\n",
    "print(neuronLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will loop through each of the 420 trials, leaving that ith trial out in turn and training with the remaining 419 trials. \n",
    "\n",
    "Within this loop, you will: \n",
    "* calculate the category average firing rate pattern for each of the 7 objects\n",
    "* compute the correlation between the held-out test pattern and each of the category average\n",
    "* select the category with the highest correlation as the predicted category\n",
    "* check if the predicted category matches the category of the held-out item\n",
    "* update the accuracy vector with a 1 if the category was correctly chosen, and 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data storage for accuracy\n",
    "accuracy = np.zeros() \n",
    "\n",
    "# Loop through each trial\n",
    "for i in range():\n",
    "    \n",
    "    # define the ith point as the test point and store its corresponding class\n",
    "    testPoint = \n",
    "    testPoint = testPoint + (.0000000001 * np.random.rand(18)) # to make correlations nicer for firing rates=0\n",
    "    trueCategory = \n",
    "    \n",
    "    # creating training data out of the remaining 419 points (no need to change anything)\n",
    "    copyData = np.delete(neuronData, i, 0)\n",
    "    copyInds = np.delete(neuronInds, i, 0)  \n",
    "    \n",
    "    # create storage for the correlations of the test item with each object\n",
    "    testCorr = np.zeros()\n",
    "    \n",
    "    # Initialize counter to index by image class (goes from 1-7)\n",
    "    ID = 1\n",
    "    \n",
    "    # Loop through each object; calculate the mean firing pattern, and compute correlation to testPoint\n",
    "    for j in range(len(neuronLabels)):\n",
    "        # find all of the training trials for the jth object\n",
    "        jGroup, = np.where()\n",
    "        \n",
    "        # use these indices to create a N-trials by 18-point matrix\n",
    "        jData = copyData[]\n",
    "        \n",
    "        # compute the mean over trials to create an average 18-point firing pattern\n",
    "        jData = np.mean()\n",
    "        \n",
    "        # increment ID\n",
    "        ID += 1\n",
    "        \n",
    "    # Choose the category with the highest correlation as the predicted class\n",
    "    # Hint: remember that predClass gives indices that are zero-indexed\n",
    "    predClass, = np.where()\n",
    "    \n",
    "    # Conditional to check if this is correct and updates accuracy vector accordingly\n",
    "    \n",
    "# print the overall results\n",
    "print(np.mean(accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have correctly implemented this procedure, you will get an accuracy of around 18-19%. How does this correspond to the level that you would expect through random guessing? How might you test whether statistically significantly higher than random guessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
